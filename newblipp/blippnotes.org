* blipp

IP, UDP, TCP stats

table stuff, leave it to INSTOOLs

minimize "touchpoints" with gush vs flack

its just a measurement store.... it doesn't make the garbage, it just
drives the truck

how do things look in UNIS?

service registration - installed but disabled will be there
ahmed will do an example instance of service schema for blipp or unis

When blipp starts:
gets service json
apply config
check local cache for metadata
query unis for metadata
create metadata for those not found
create collections for unknown
blipp's config will include MS location
TTL?
blipp metrics +mem +disk

** disk metrics
fields may wrap... watch for this
no locks while modifying counters
in 2.6 there are per-CPU counters so no locking becomes less of an
issue


Diskstats:
|               1 |            2 |            3 |                4 |                5 |             6 |               7 |                8 |               9 |              10 |                11 |
| reads completed | reads merged | sectors read | ms spent reading | writes completed | writes merged | sectors written | ms spent writing | ios in progress | ms spent in ios | weighted ms in io |

For partitions in 2.6 there are only 4 fields:
|            1 |            2 |             3 |               4 |
| reads issued | sectors read | writes issued | sectors written |

In 2.6.25, the full statistic set is again available for partitions

** TODO cpu metrics
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:user" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:system" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:nice" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:iowait" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:hwirq" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:swirq" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:steal" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:utilization:guest" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:load:onemin" ]
blipp-mds-cpu.js:	"eventTypes": [ "ps:tools:blipp:linux:cpu:load:fivemin" ]
blipp-mds-cpu.js:	"eventTypes": ["ps:tools:blipp:linux:cpu:load:fifteenmin" ]


* call notes 5/16
change schedule while running
new code base - migrate good stuff
output as a module don't kill xsp compat
registration

* what does blipp need to do
its a scheduler for a variety of probes basically
reads config for probes and runs them at the specified interval
it registers itself with UNIS
it fills UNIS in with extra info, like cpu cores and status
it exports data to the MS or to an XSP daemon


* issues
** how are we doing metadata ids? hash of metadata?
answer: getting them from UNIS... unless there is no UNIS, then blipp makes them up

** DONE metadata collection interval - rejected
Consider having no collection interval in metadata... collection interval should
be clear from timestamps. It could change without chaning the metadata. A tool
used to view the data could separate out different sections with different
intervals, but that would require reading all the data.

** DONE standardize config files - how are we gonna do it?
just python files for now

** metadata timestamp
its called nanoseconds in ahmed's big html tar, but I think it should be seconds?

** rel - what is it?

** content-type... why is it so long?

** MS documentation on github 

** There is no GET /collections/{mid} ?

** It'd be cool if you could query unis by sending some json instead of constructing a URL

** create multiple collections with one post in MS

** how can there be a conflict(409) when posting to /events in MS? timestamp collision?

** can you have an MS without UNIS?

** maybe having COLLECTION_TIME and the scheduler is not necessary... could this create weird states?

* structure
** general
bootstrapper and psconfig configure and start scheduler
scheduler runs probes
probes send data to module which sends to MS

** scheduler 
infinite loop:
  read conf
  compare to old conf
  start/restart/stop probes as needed
    we're going to be getting config from UNIS, maybe pSConfig can
    let us know when stuff changes so we aren't constantly polling?
  The scheduler needs to know where each probe and its conf is so that it knows
  when to start/stop/restart probes by when their conf changes

** probes
each probe collects and formats its data.  probes figure out their metadata by
checking disk cache and querying UNIS. - NOPE UNISClient figures out metadata
stuff

probes hand formatted data/metadata to a module that sends to the MS with all the appropriate HTTPishness.

* metadata
** to post:
subject - yes in config somewhere OR sent to you by the probe
parameters - yes determined by config, or by probe if requested config is impossible
eventType - yes determined by the probe

id - unis will create
timestamp - unis will create
selfRef - created by unis

* config
UNIS_URL
UNIS_PORT
LOCAL_METADATA_CACHE
SUBJECT

MS_URL
MS_PORT
DEFAULT_TTL

** meausurement config
collection interval, summarization, etc

* DONE refactor unis_client and ms_client - decided not to go this way
*** they should only take in pure json strings and be very simple
*** one post method that takes url extension and data (and maybe headers)
*** their job is just to use the requests library, and handle the response appropriately

* TODO turn into a module... blipp dir with __init__.py etc

* TODO fix SchedObj so lack of probe_settings doesn't throw error - maybe done need test
* TODO classize Scheduler and decide on settings file handling - ugh

* TODO metadata caching
* TODO other probes
* TODO clean up response handling
_handle_response just does logging, doesn't return anything... maybe don't even need it
return status_code always
* TODO bring in XSP code
* TODO fix measurement timing to be sourced at the start time - eliminate drift
* New Structure emmer effers
** blipp module
*** scheduler is a submodule 
called sched.py loads settings.py which contains PROBES=[...] a list of probe
names, and the CHECK_INTERVAL, the time between subsequent checks of whether the
settings files have changed. A SchedObj is created for each probe which runs it
at the configured scheduled intervales.

1) set up SchedObjs
2) start them
**** TODO 3) check settings - 
   - if check_interval is different, just update its value
   - if probes is different
     + stop probes no longer in the list
     + start new probes


*** probes are submodules
has name like "cpu.py", and settings file like "cpu_settings.py"
**** probe_settings
each probe_settings file has a number of standard settings like collection interval and reporting interval,
as well as a kwargs dictionary which gets passed to the Probe
each probe must define its event types in EVENT_TYPES in its probe_settings file 

**** Class called "Probe"
has a method "get_data"
get_data reports data in the format {"metric_name":value, "metric_name2":value2, ...} OR
{"subject1":{"metric_name":value, "metric_name2":value2, ...}, "subject2":{...}, ...}
without subjects, tahe subject for metadata is assumed to be the node in the global settings.py file

**** cpu.py
for getting load values (from some shinken code):
(d1, d2, d3) = os.getloadavg()

*** settings files
These are straight python files and just have variables defined within (all caps
by convention). Some variables are dictionaries, some are lists, some are
strings, and some are numbers (float or int). There is a global settings.py file
which contains any settings that apply to blipp as a whole, and any probe
specific settings that the user wishes to apply to all probes that don't have
that setting defined specifically in their probe_settings.py file.

*** UnisInstance
contact point for unis
caches metadata
pretends to be unis if no unis instance is specified

* External libraries
** python requests
easy_install or pip install
** python-ethtool
needed to sudo apt-get install libnl-dev
http://dsommers.fedorapeople.org/python-ethtool/python-ethtool-0.7.tar.bz2
http://dsommers.fedorapeople.org/python-ethtool/python-ethtool-libnl-1.0-support.patch
from the python-ethtool dir: $ patch -p1 < ../python-ethtool-libnl-1.0-support.patch
*** add in get_speed function to ethtool.c
#+BEGIN_SRC
static PyObject *get_speed(PyObject *self __unused, PyObject *args)
{
	struct ifreq ifr;
	int fd, err;
	struct ethtool_cmd edata;
	char *devname;
	if (!PyArg_ParseTuple(args, "s", &devname))
		return NULL;

	/* Setup our control structures. */
	memset(&ifr, 0, sizeof(ifr));
	strncpy(&ifr.ifr_name[0], devname, IFNAMSIZ);
	ifr.ifr_name[IFNAMSIZ - 1] = 0;
	ifr.ifr_data = &edata;
	edata.cmd = ETHTOOL_GSET;


	/* Open control socket. */
	fd = socket(AF_INET, SOCK_DGRAM, 0);
	if (fd < 0) {
          PyErr_SetString(PyExc_OSError, strerror(errno));
          return NULL;
	}

	/* Get current settings. */
	err = ioctl(fd, SIOCETHTOOL, &ifr);
        if (err < 0) {
          PyErr_SetString(PyExc_OSError, strerror(errno));
          return NULL;
        }
	
	close(fd);
        return PyInt_FromLong((long) edata.speed);
}
#+END_SRC
setup.py install

** netlogger
$ sudo pip install netlogger
* Major changes
** remove time logic from SchedObj
have methods for collect, report etc, but let the scheduler call them.
Scheduler will create the SchedObj (which should now be called a ProbeObj), and
let it read all its config. It will then create a subprocess for each ProbeObj
that runs collect and report (logs should show times) at ProbeObj.ci and ProbeObj.ri, and figures out how
long to sleep.

** combine unis_client and ms_client
it should handle:
response handling - should log time
default headers
get method, post method

can have a metadata handler and a data handler (the collector)
