#!/usr/bin/env python
"""
Basic Lightweight Periscope Probe (BLiPP) daemon.
"""
__rcsid__ = "$Id$"
__author__ = "Dan Gunter <dkgunter@lbl.gov>"

# Std library imports
import glob
from itertools import izip
import logging
import optparse
import os
import pprint
import signal
import socket
import sys
import time
import traceback

# Third party
import simplejson as json

# Local imports
from blipp import base, probes, util, xsplib, output
from blipp.util import bson_encode, bson_decode
from blipp.eventtypes import * # just type defs, no real code

## Constants and globals
## ---------------------

# Stop things that are in a loop
g_stop = False

# Logger
g_log = None

## Classes and functions
## ---------------------

class ConnInfo:
    def __init__(self, tcp_tuple, task_id):
        self._c = tcp_tuple
        self._id = task_id
    def as_dict(self):
        return {'LocalAddress': self._c[0],
                'LocalPort' : int(self._c[1]),
                'RemAddress': self._c[2],
                'RemPort' : int(self._c[3]),
                'task_id' : self._id }

class Web10GConnections:
    """Keep track of open connections for Web10G queries.
    """
    def __init__(self):
        self._connections = { }
        self._added = [ ]

    def _extract(self, obj):
        """Find and yield network items, one at a time.
        """
        for block in obj:
            for meta_block in block[u'meta']:
                if meta_block[u'event_type'] == u'xfer.xsp.xio':
                    sbj = meta_block.get(u'subject', { })
                    if sbj[u'type'] == u'network':
                        tcp_ident = [sbj['src'], int(sbj['sport']), sbj['dst'], int(sbj['dport'])] 
                        id_ = sbj.get('task_id','ANY')
                        yield tcp_ident, tuple(tcp_ident + [id_]), id_

    def conn_open(self, data, type_=None):
        """Called when an XSP message comes in for a new connection.

        Args:
            data - BSON object from XSP
            type_ - XSP option type
        """
        g_log.debug("conn_open, data='%s'", str(data))
        for tcp_ident, key, task_id in self._extract(data):
            t = probes.TCPStats(*tcp_ident)
            t.meta['task_id'] = task_id
            self._connections[key] = (t, ConnInfo(tcp_ident, task_id))

    def conn_close(self, data, type_=None):
        """Called when an XSP message comes in to close a connection.

        Args:
            data - BSON object from XSP
            type_ - XSP option type
        """
        g_log.debug("conn_close, data='%s'", str(data))
        for tcp_ident, key, task_id in self._extract(data):
            try:
                del self._connections[key]
            except KeyError:
                g_log.warn("conn_close.failed key={k}".format(k=key))

    def meta(self):
        """List of metadata instances, each of which is a dictionary.
        """
        # same as probes.TCPStats.TCP_TUPLE_NAMES
        return [conn.as_dict()
                for k, (_, conn) in self._connections.iteritems()]

    def stats(self):
        """List of TCPStats instances, one per connection.
        """
        return [stats for (stats, _) in self._connections.itervalues()]

def on_kill(signo, frame):
    """Signal handler for a graceful exit.
    """
    global g_stop
    g_log.warn("killed, signal=%d", signo)
    g_stop = True

def on_hup(signo, frame):
    return

class BlippDaemon:
    """Blippd instance to run.
    """
    def __init__(self, sink=None, samples_per_iter=None,
             dt=None, proc=None, pids=[ ], ifaces=[ ], xsp_rcv_port=-1):
        """Initialize variables

        Args:
          `sink` - output.Sink instance
        """
        assert samples_per_iter is not None, "samples_per_iter not defined"
        assert dt is not None, "dt not defined"

        self.nsamples = samples_per_iter
        self.dt, self.proc, self.pids, self.ifaces = dt, proc, pids, ifaces
        self._sink = sink
        self._debug_mode = True
        g_log.info("start")
        self._iface_meta = { }
        self.mblocks = { } # metadata blocks

        if probes.Web10G is None:
            g_log.info("web10g, on=False")
            self.web10g = False
        else:
            g_log.info("web10g, on=True")
            self.web10g = True
            self._setup_web10g(xsp_rcv_port)

        self.start_time = time.time()

        # base meta blocks
        self.mblocks['host'] = base.MetaBlock(
            event_type=et_paste(BASE_ET,'host'),
            subject=dict(hostname=probes.get_hostname(),
                         ipv4=probes.get_hostip()))
        self.mblocks['os'] = base.MetaBlock(
            event_type=et_paste(BASE_ET,'os'),
            subject=probes.get_uname(),
            parent=self.mblocks['host'].ident)
        self.mblocks['timeseries'] = base.MetaBlock(
            event_type=et_paste(BASE_ET, 'timeseries'),
            subject={},
            parent=self.mblocks['os'].ident,
            params=dict(ts=self.start_time, dt=self.dt))
        # list of above meta block names, so they can be
        # added to each data block
        self._root_metas = 'host', 'os', 'timeseries'
        # set parent-id to the last non-leaf in chain
        self._root_id = self.mblocks[self._root_metas[-1]].ident

        self._setup_procnetdev()
        self._setup_cpuinfo()
        self._setup_pidinfo(pids)
        self._sess = base.Session() # context across Blocks

    def _setup_cpuinfo(self):
        """Init the CPU info
        """
        g_log.info("setup.cpuinfo.begin")
        self.mblocks['cpu'] = { }
        self._cpu_info = probes.CPUInfo(proc=self.proc)
        g_log.info("setup.cpuinfo.end")

    def _setup_pidinfo(self, pids):
        """Per-process stats initialization for each process ID listed
        in 'pids'.
        """
        g_log.info("setup.pidinfo.begin")
        # Create list of ProcessInfo objects, to poll later
        self._pid_info = [probes.ProcessInfo(p, proc=self.proc) for p in pids]
        self.mblocks['pid'] = { }
        # Create metadata blocks for each PID, in same order as _pid_info
        for pi in self._pid_info:
            self.mblocks['pid'][pi] = base.MetaBlock(
                event_type='host.process',
                subject=pi.get_meta()[0],
                parent=self._root_id)
        g_log.info("setup.pidinfo.end")

    def _setup_procnetdev(self):
        """/proc/net/dev initialization. Set interface metadata.
        """
        g_log.info("setup.procnetdev.begin")
        parent = self._root_id
        nd_stats = probes.get_net_dev(proc=self.proc, active=self.ifaces)
        im, mb = probes.get_iface_meta(parent, nd_stats,
                                       ts=self.start_time, dt=self.dt)
        self.mblocks['if'] = { }
        for interface, value in im.iteritems():
            self.mblocks['if'][interface] = value
        self._all_if_mblocks = mb
        g_log.info("setup.procnetdev.end")

    def _setup_procstat(self, b, hdata):
        """Initialize /proc/stat monitoring.
        """
        g_log.info("setup.procstat.begin")
        self.mblocks['cpu'] = { } # metadata section for processors
        # Add metadata for each processor (CPU)
        for cpu in xrange(len(hdata)):
            cmblock = base.MetaBlock(
                event_type=et_paste(CPU_ET, self._cpu_info.CPU_TYPE),
                subject={'index':cpu})
            # metadata for whole CPU has core index == -1
            self.mblocks['cpu'][(cpu, -1)] = cmblock
            b.meta.append(cmblock)
            # Add metadata for each core in the CPU
            for core in xrange(len(hdata[cpu][1])):
                mblock = base.MetaBlock(
                    event_type=et_paste(CPU_ET, self._cpu_info.CORE_TYPE),
                    subject={'index':core},
                    parent=cmblock.ident)
                self.mblocks['cpu'][(cpu, core)] = mblock
                b.meta.append(mblock)
        g_log.info("setup.procstat.end")

    def _setup_web10g(self, port):
        """Initialize settings for web10g receiving.

        Note that the metadata blocks depend on asynchronous messages,
        so unlike other _setup_*() methods, they are empty when this
        method finishes.
        """
        g_log.info("setup.web10g.begin")
        if os.geteuid() != 0:
            g_log.warn("web10g.permissions, msg=\"non-root user\"")
        self.web10g_conn = Web10GConnections()
        self.xsp_srv = xsplib.XSPServer(
            'localhost', port,
            cb_map={ xsplib.XSP_MSG_XIO_NEW_XFER : self._xsp_conn_new,
                     xsplib.XSP_MSG_XIO_END_XFER : self._xsp_conn_end,
                     None : self._xsp_ignore})
        self.mblocks['web10g'] = { }
        g_log.info("setup.web10g.end")

    def _xsp_ignore(self, type_=None, data=None):
        """Ignore an XSP message, but log a warning.
        """
        if type_:
            g_log.warn("xsp-message-ignored type=%s", type_)

    def _xsp_conn_new(self, type_=None, data=None):
        self._xsp_fwd(data, self.web10g_conn.conn_open)

    def _xsp_conn_end(self, type_=None, data=None):
        self._xsp_fwd(data, self.web10g_conn.conn_close)

    def _xsp_fwd(self, data, func):
        """Parse a BSON data message and forward to 'func'.

        Args:
           data - Raw data bytes
           func - Function to call to process BSON object

        Raises:
           ValueError - If there is a problem decoding or parsing the data
                        down to the level of its type.
        """
        if data is None:
            return
        try:
            obj = bson_decode(data)
        except Exception, err:
            raise ValueError("web10g decode failed in BSON decode: %s" % err)
        func(data=obj)

    def _sample_procnetdev(self, b, hdr):
        """Get interface statistics from /proc/net/dev
        """
        g_log.debug("sample.procnetdev.begin")
        ts = time.time()
        stats = probes.get_net_dev(proc=self.proc)
        # add data for each interface.
        for iface, ifmeta in self.mblocks['if'].iteritems():
            # add a data block for each type of value for this interface
            for value_type in stats[iface]:
                uri = et_paste(NETDEV_ET, value_type)
                if hdr:
                    self._sess.set_meta_block(uri, ifmeta)
                mblock = self._sess.get_meta_block(uri, ifmeta)
            dblock = base.DataBlock(meta=mblock)
            # add timestamp/value pairs
            for v in stats[iface][value_type]:
                dblock.add_value(ts, v)
                b.add_data_block(dblock)
        g_log.debug("sample.procnetdev.end")

    def _sample_procstat(self, b, hdr):
        """Sample process values from /proc/stat
        """
        g_log.debug("sample.procstat.begin")
        ts, i = time.time(), 0
        hdata = self._cpu_info.get_data()
        # add data for each type of value
        # first time, make new cpu/core type for i-th cpu or core
        if hdr:
            self._setup_procstat(b, hdata)
        # For each processor (CPU)
        for cpu_i in xrange(len(hdata)):
            for k, v in hdata[cpu_i][0].iteritems():
                # fetch associated metadata block for the
                # processor (core == -1), and data type
                uri = et_paste(CPU_STAT_ET, self._cpu_info.CPU_TYPE, k)
                mkey = self.mblocks['cpu'][(cpu_i, -1)]
                if hdr:
                    mblock = self._sess.set_meta_block( uri, mkey)
                mblock = self._sess.get_meta_block(uri, mkey)
                # hook metadata block to data block, and add it
                dblock = base.DataBlock(meta=mblock)
                dblock.add_value(ts, v)
                b.add_data_block(dblock)
            # For each core in the processor
            for core_i in xrange(len(hdata[cpu_i][1])):
                for k, v in hdata[cpu_i][1][core_i].iteritems():
                    # fetch assoc. metadata block for this core & value type
                    uri = et_paste(CPU_STAT_ET, self._cpu_info.CORE_TYPE, k)
                    mkey = self.mblocks['cpu'][(cpu_i, core_i)]
                    if hdr:
                        mblock = self._sess.set_meta_block( uri, mkey)
                    mblock = self._sess.get_meta_block(uri, mkey)
                    # hook metadata block to data block, and add it
                    dblock = base.DataBlock(meta=mblock)
                    dblock.add_value(ts, v)
                    b.add_data_block(dblock)
        g_log.debug("sample.procstat.end")

    def _sample_procpid(self, b, hdr):
        """Sample values from /proc for PIDs of interest.
        """
        g_log.debug("sample.procpid.end")
        ts = time.time()
        # Loop over each PID obj and its assoc. metadata
        for pi, pi_meta in izip(self._pid_info, self.mblocks['pid']):
            # Loop over all data values returned
            for value_type, value in pi.get_data().iteritems():
                # Get associated metadata block
                uri = et_paste(PID_ET, value_type)
                if hdr:
                    mblock = self._sess.set_meta_block(uri, pi_meta)
                mblock = self._sess.get_meta_block(uri, pi_meta)
                # Create data block with metadata block and add it
                dblock = base.DataBlock(meta=mblock)
                dblock.add_value(ts, value)
                b.add_data_block(dblock)
        g_log.debug("sample.procpid.end")

    def _sample_web10g(self, b):
        """Sample Web10G statistics for each monitored connection.
        """
        g_log.debug("sample.web10g.begin")
        ts = time.time()
        # For each set of connections
        for tcpconn in self.web10g_conn.stats():
            tcpstats = tcpconn.read()
            g_log.debug("_sample_web10g, tcpstats '%s'", str(tcpstats))
            # For each connection in set
            for conn_key, tcpinfo in tcpstats.iteritems():
                parent_meta = self.mblocks['web10g'][conn_key]
                # For each value type for the connection
                for value_type, value in tcpinfo.iteritems():
                    # Get associated metadata block
                    uri = et_paste(NET_TCP_ET, value_type)
                    # XXX(fernandes): the header for web10g needs to be set
                    #   every time a new connection is setup, not only for first sample.
                    # TODO: move logic into conn_open and conn_close?
                    try:
                        mblock = self._sess.get_meta_block(uri, parent_meta)
                    except KeyError:
                        mblock = self._sess.set_meta_block(uri, parent_meta)
                    # Create data block with metadata block and add it
                    dblock = base.DataBlock(meta=mblock)
                    dblock.add_value(ts, value)
                    b.add_data_block(dblock)
        g_log.debug("sample.web10g.end")

    def _xsp_rcv(self, b, timeout):
        """Receive messages on XSP listener about which
        connections to monitor with Web10G.
        """
        g_log.debug("xsp-rcv.begin")
        self.xsp_srv.loop(timeout=timeout, count=1)
        # add new connection metadata (if any)
        md = self.web10g_conn.meta()
        for item in md:
            # build key for the given metadata info
            key = tuple([item[name] for name in probes.TCPStats.TCP_TUPLE_NAMES])
            prev_block = self.mblocks['web10g'].get(key, None)
            if prev_block is None:
                # if this is a new connection, add its metadata
                g_log.info("web10g.new-connection, key=%s", str(key))
                block = base.MetaBlock(event_type=NET_TCP_ET, subject=item)
                self.mblocks['web10g'][key] = block
                b.meta.append(block)

            # in either case, update existing metadata
            # XXX(fernandes): actually don't, generating a new mid is not good.
            #self.mblocks['web10g'][key] = block
        g_log.debug("xsp-rcv.end")

    def iterate(self, iteration):
        """Run one iteration, which may contain multiple samples.
        """
        g_log.info("iterate.begin, iter=%d nsamples=%d", iteration, self.nsamples)
        b = base.Block()
        self._sess.set_block(b)
        # web10g receiver timeout, in sec
        if self.web10g:
            web10g_tmout = 0.2
        else:
            web10g_tmout = 0
        for i in xrange(self.nsamples):
            g_log.debug("iterate.sample.begin, sample=%d", i)
            sampnum = iteration * self.nsamples + i + 1
            is_hdr = (sampnum == 1)
            if self.web10g:
                # check for XSP server messages (for web10G)
                # try several times w/short timeout because there are
                # several messages per connection
                for _ in xrange(5):
                    self._xsp_rcv(b, web10g_tmout)
            # for host data, add metadata on first iteration
            if is_hdr:
                for block_key in self._root_metas:
                    b.meta.append(self.mblocks[block_key])
                map(b.meta.append, self.mblocks['pid'])
                map(b.meta.append, self._all_if_mblocks)
            # Gather samples
            if g_stop:
                break # test for async. stop
            self._sample_procnetdev(b, is_hdr)
            self._sample_procstat(b, is_hdr)
            self._sample_procpid(b, is_hdr)
            if self.web10g:
                self._sample_web10g(b)
            if g_stop:
                break
            # sleep for sampling interval, minus time spent
            # waiting for web10g messages, if any
            time.sleep(self.dt - web10g_tmout)
            g_log.debug("iterate.sample.end, i=%d", i)
        # Done with inner loop. Send message.
        self._sink.add(b.as_dict())
        b.clear()
        g_log.info("iterate.end")
        return 0

def main():
    """Program entry point.
    """
    global g_stop, g_log
    g_stop = False
    status = 0
    
    usage = "%prog [options]"
    desc = ' '.join(__doc__.split())
    parser = optparse.OptionParser(usage=usage, description=desc)
    parser.add_option("-d", "--dir", dest="proc", action="store", default="/proc",
                      help="Root of Linux 'proc' files (default=%default)")
    parser.add_option("-f", "--fg", dest="foreground", action="store_true", default=False,
                      help="Run in the foreground, don't fork into background")
    parser.add_option("-g", "--debug", dest="dbg", action="store_true", default=False,
            help="Debug mode: dump to stdout instead of connecting to a host. Implies -f/--fg.")
    parser.add_option("-H", "--host", dest="host", default="localhost",
                      help="XSP receiver host (default=%default)")
    parser.add_option("-l", "--log", dest="logfile", default=None,
                      help="Log file (default=/tmp/blippd.<pid>.log, or stderr if -f/--fg)")
    parser.add_option("-p", "--port", dest="port", action="store", type="int", default=5006,
                      help="XSP receiver port (default=%default)")
    parser.add_option("-L", "--listen-port", dest="lport", action="store", type="int", default=5007,
                      metavar="PORT",
                      help="Port to listen for XSP messages (default=%default)")
    parser.add_option("-v", "--verbose", dest="vb", action="count", default=0,
                      help="More verbose messages")
    group = optparse.OptionGroup(parser, "Sampling options")
    group.add_option("--dt", dest="dt", type="float", default=1.0,
                     help="Sampling interval in seconds (default=%default)")
    group.add_option("--iter", dest="iter", type="int", default=0,
                     help="Number of iterations, 0=forever (default=%default). "
                     "One message is sent to XSP for each iteration.")
    group.add_option("--samples", dest="samples", type="int", default=1,
                     help="Number of samples per iteration (default=%default)")
    parser.add_option_group(group)
    group = optparse.OptionGroup(parser, "Probe options")
    group.add_option("--pid", dest="pids", type="int", action="append", default=[ ],
                     metavar="PID",
                     help="Process ID for which to get detailed statistics. Repeatable.")
    group.add_option("--if", dest="ifs", type="str", action="append", default=[ ],
                     metavar="IFace",
                     help="Interface name for which to get detailed statistics. Repeatable.")
    options, args = parser.parse_args(sys.argv[1:])

    # Logging. Set up base logger properties.
    g_log = logging.root
    logfmt = logging.Formatter("%(asctime)s %(levelname)-9s %(message)s")
    if options.vb > 1:
        g_log.setLevel(logging.DEBUG)
    elif options.vb > 0:
        g_log.setLevel(logging.INFO)
    else:
        g_log.setLevel(logging.WARN)
    if options.logfile:
        try:
            hndlr = logging.FileHandler(options.logfile)
            hndlr.setFormatter(logfmt)
            g_log.addHandler(hndlr)
        except:
            parser.error("Could not log to file: %s" % options.logfile)
            sys.exit(1)
    elif options.foreground or options.dbg:
        hndlr = logging.StreamHandler()
        hndlr.setFormatter(logfmt)
        g_log.addHandler(hndlr)
    else:
        tmpfile = "/tmp/blippd.%d.log" % os.getpid()
        try:
            hndlr = logging.FileHandler(tmpfile)
            hndlr.setFormatter(logfmt)
            g_log.addHandler(hndlr)
        except:
            parser.error("Could not log to file: %s" % tmpfile)
            sys.exit(1)
    # Now initialize loggers in imported modules
    base.init_logging()

    # Signal handlers
    util.handleSignals(
        (on_kill, ('SIGTERM', 'SIGINT', 'SIGUSR2')),
        (on_hup, ('SIGHUP',)) )

    # Set up data sink
    sink = None
    if options.dbg:
        daemonize = False
        sink = output.Print_sink()
    else:
        sink = output.XSP_sink(options.host, options.port)

    # Daemonize
    status = 0
    if not (options.dbg or options.foreground):
        g_log.debug("daemonize.start")
        try:
            util.daemonize(g_log, root_log=logging.getLogger(''), close_fds=False)
        except Exception, err:
            g_log.critical("daemonize.error, msg=%s", str(err))
            status = -1
        g_log.debug("daemonize.end, status=%d", status)

    if status != 0:
        g_log.info("run.end, status=%d", status)
        return status

    # Iteration count, <0 means 'forever'. Note: At 1 sec. intervals,
    # sys.maxint on my Mac is over 290 billion years
    if options.iter <= 0:
        options.iter = sys.maxint

    # Run the program
    try:
        proc = probes.Proc(dirname=options.proc)
        blippd = BlippDaemon(sink, samples_per_iter=options.samples,
                             dt=options.dt, proc=proc, pids=options.pids,
                             xsp_rcv_port=options.lport)
        for i in xrange(options.iter):
            if g_stop:
                break
            blippd.iterate(i)
    except Exception, err:
        status, errmsg = -1, str(err)
        if "pipe" in errmsg:
            tb = "Caught SIGPIPE"
        else:
            tb = traceback.format_exc()
        g_log.fatal("probe.error, msg=%s\n%s", errmsg, tb)
    finally:
        sink.close()
        sys.exit(0)

    g_log.info("run.end, status=%d", status)
    return(0)

if __name__ == '__main__':
    sys.exit(main())
